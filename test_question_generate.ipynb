{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from question_generater import QuestionGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "qg_600 = QuestionGenerator(dataset='600',question_threshold=60)\n",
    "qg_150 = QuestionGenerator(dataset='150',question_threshold=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "\n",
    "for i in range(120):\n",
    "    user_id = str(i)\n",
    "    # generate a list of 60 1s and 15 0s to decide when to use two question generator\n",
    "    # 1 means use two question generator\n",
    "    # 0 means use one question generator\n",
    "    random_list = [1]*120 + [0]*30\n",
    "    # shuffle the list\n",
    "    random.shuffle(random_list)\n",
    "    # output txt containing chinese\n",
    "    with open('data/questions/preset/{}.txt'.format(user_id), 'w',encoding='utf-8') as f:\n",
    "        for i in range(150):\n",
    "            if random_list[i] == 1:\n",
    "                question = qg_600.get_question(user_id)\n",
    "            else: \n",
    "                question = qg_150.get_question(user_id)\n",
    "            #save to file, each question is a json, so save it in a line and can be parsed into json when read in the line\n",
    "            if question[\"type\"]!=\"finished\":\n",
    "                f.write(json.dumps(question, ensure_ascii=False)+\"\\n\")\n",
    "        f.write(json.dumps({\"type\":\"finished\"}, ensure_ascii=False)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18060\n"
     ]
    }
   ],
   "source": [
    "# read in the 100 question files from selected directory\n",
    "import os\n",
    "import json\n",
    "\n",
    "all_question_list = []\n",
    "\n",
    "\n",
    "for filename in os.listdir(\"data/questions/preset/\"):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        with open(\"data/questions/preset/\" + filename, \"r\") as f:\n",
    "            for line in f:\n",
    "                all_question_list.append(json.loads(line))\n",
    "print(len(all_question_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in tagged file\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"src/instances_Inception_600_with_tag.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“flask”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n flask ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# statistics on the appearance time of each expression in the all quesion list\n",
    "example_times = {}\n",
    "instance_times = {}\n",
    "q150_times = 0\n",
    "q600_times = 0\n",
    "for question in all_question_list:\n",
    "    if question[\"type\"] == \"finished\":\n",
    "        continue\n",
    "    if question[\"type\"] == \"1v1\":\n",
    "        if question[\"dataset\"]==\"150\":\n",
    "            q150_times += 1\n",
    "        else:\n",
    "            q600_times += 1\n",
    "        example_instance = question[\"example_instance\"]\n",
    "        if example_instance not in example_times:\n",
    "            example_times[example_instance] = 0\n",
    "        example_times[example_instance] += 1\n",
    "    elif question[\"type\"] == \"1\":\n",
    "        instance = question[\"instance\"]\n",
    "        if instance not in instance_times:\n",
    "            instance_times[instance] = 0\n",
    "        instance_times[instance] += 1\n",
    "    else:\n",
    "        if question[\"dataset\"]==\"150\":\n",
    "            q150_times += 1\n",
    "        else:\n",
    "            q600_times += 1\n",
    "        '''\n",
    "        example_instances = question[\"example_instances\"]\n",
    "        for example_instance in example_instances:\n",
    "            if example_instance not in example_times:\n",
    "                example_times[example_instance] = 0\n",
    "            example_times[example_instance] += 1\n",
    "        '''\n",
    "print(f\"150 question number: {q150_times}\")\n",
    "print(f\"600 question number: {q600_times}\")\n",
    "print(f\"example expression number: {len(example_times)}\")\n",
    "print(f\"instance expression number: {len(instance_times)}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# use a histogram to show the distribution of the appearance time of each expression\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.hist(list(example_times.values()), bins=100)\n",
    "plt.show()\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.hist(list(instance_times.values()), bins=100)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“flask”的单元格需要ipykernel包。\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n flask ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# statistics on the distance ranking/similarity on 1v1 pairs\n",
    "# if not ideal change the ability pair selection method\n",
    "\n",
    "# read in tagged file\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"src/instances_Inception_600_with_similarity.csv\")\n",
    "\n",
    "similarity_list = df[\"similarity\"].tolist()\n",
    "for question in all_question_list:\n",
    "    if question[\"type\"] == \"1v1\" and question[\"dataset\"]==\"600\":\n",
    "        example = question[\"example_instance\"]\n",
    "        instance = question[\"instance\"]\n",
    "        example_idx = df[df[\"instance\"] == example].index[0]\n",
    "        instance_idx = df[df[\"instance\"] == instance].index[0]\n",
    "        similarity = similarity_list[example_idx][\"similarity_\"+str(instance_idx)]\n",
    "        similarity_list.append(similarity)\n",
    "\n",
    "# use histogram to show the distribution of similarity\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(similarity_list, bins=50)\n",
    "plt.show()\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
